{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Processing and Normalizing Images \n",
      "\n",
      "Time Elapsed to Process and Normalize Data: 0.0137 seconds!\n",
      "\n",
      "#################### Creating Data From Images \n",
      "\n",
      "Time Elapsed to Create Data: 11.4738 seconds!\n",
      "\n",
      "#################### Training RandomForest Classifier #1\n",
      "\n",
      "Testing RandomForest with 0.8591% Accuracy in 3.7848 seconds with 100 trees!\n",
      "\n",
      "Testing RandomForest with 0.8727% Accuracy in 11.2050 seconds with 200 trees and entropy!\n",
      "\n",
      "#################### Training kNearestNeighbor Classifier #1\n",
      "\n",
      "Testing kNN with 0.6955% Accuracy in 0.0005 seconds with 7 neighbors, leaf size 100, and distance method!\n",
      "\n",
      "Testing kNN with 0.6455% Accuracy in 0.0002 seconds with 5 neighbors!\n",
      "\n",
      "#################### Conclusion \n",
      "\n",
      "Over 1 trial(s), default RandomForest has an average of 0.8591% accuracy.\n",
      "\n",
      "Over 1 trial(s), modded RandomForest has an average of 0.8727% accuracy.\n",
      "\n",
      "Over 1 trial(s), default kNN has an average of 0.6455% accuracy.\n",
      "\n",
      "Over 1 trial(s), modded kNN has an average of 0.6955% accuracy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import Bunch\n",
    "import time, string, random\n",
    "\n",
    "def poke_predict(n, otherCases):\n",
    "    # poke_predict takes an n INTEGER to determine how many times the user wants to iterate the machine learning process\n",
    "    # if n = 1, the machine learning will be run once, and if n = 100, machine learning will be run 100 times\n",
    "    # It is highly recommended to not use any n value higher than 10 as it will take a very long time.\n",
    "    # otherCases is a BOOLEAN that signifies whether or not you want the other extra cases to be tested\n",
    "    # By default, it is False, but you can set it to True. However, it will take much longer. \n",
    "    print(\"#################### Processing and Normalizing Images \\n\")\n",
    "\n",
    "    # Specifies the directory of all the images\n",
    "    image_dir_path = 'dataset'\n",
    "    # Declares the four lists that will be needed to create the data for machine learning\n",
    "    pokemonRGB, pokemonImage, pokemonTarget, pokemonNames = [], [], [], []\n",
    "\n",
    "    # Starts the process of normalizing all the images taken from Kaggle\n",
    "    def img_normalize():\n",
    "        # This goes through every file in the directory\n",
    "        for i, path in enumerate(Path(image_dir_path).rglob('*.*')):\n",
    "            # If the file is NOT either a png or jpg\n",
    "            if not path.parts[2][path.parts[2].index('.'):].lower() in ['.png', '.jpg', '.jpeg']:\n",
    "                # Remove the file; we don't want it\n",
    "                os.remove(path)\n",
    "            # Otherwise check if it starts with 'new' to signify that it has been normalized already\n",
    "            elif not path.parts[2].startswith('new'):\n",
    "                # Opens the image\n",
    "                with Image.open(path) as img:\n",
    "                    # Checks if the image has been normalized by height already or not\n",
    "                    if not (img.width == 64 and img.height == 64):\n",
    "                        # Generates a 3 character long string\n",
    "                        ranString = ''.join(random.choices(string.ascii_uppercase + string.digits, k=3))\n",
    "                        # Does 3 things: it resizes all the images to a 64x64 image,\n",
    "                        # Then it converts every image to RGB, so it gets rid of the Alpha channel if it has, \n",
    "                        # or other formats of images so that every image is the same\n",
    "                        # Saves every image as a new name and as a png\n",
    "                        img.resize((64,64)).convert('RGB').save(f\"{path.parts[0]}/{path.parts[1]}/new{i}-{ranString}.png\")\n",
    "                        # Removes the old image file\n",
    "                        os.remove(path)\n",
    "\n",
    "    # Starts a timer to count how long it will take to normalize images\n",
    "    start = time.perf_counter()\n",
    "    img_normalize()\n",
    "    end = time.perf_counter() \n",
    "    # On average, if the images are not normalized already, this will take about 30 seconds or so\n",
    "    # If the images are normalized already, then it should take only  0.01 to check\n",
    "    print(f\"Time Elapsed to Process and Normalize Data: {end-start:0.4f} seconds!\\n\")\n",
    "\n",
    "    print(\"#################### Creating Data From Images \\n\")\n",
    "\n",
    "    # Starts the process of turning the images into data for machine learning\n",
    "    def createData():\n",
    "        # Again, goes through every image file\n",
    "        for path in Path(image_dir_path).rglob('*.*'):\n",
    "            # Checks if a Pokemon is in a list, if not, then append\n",
    "            if path.parts[1] not in pokemonNames:\n",
    "                pokemonNames.append(path.parts[1])\n",
    "            # Appends the index value of the pokemon from pokemonNames to the pokemonTarget; think as if they correspond.\n",
    "            # If Abra was the first pokemon in pokemonNames, the first value in pokemonTarget would be 0 (because 0th index)\n",
    "            pokemonTarget.append(pokemonNames.index(path.parts[1]))\n",
    "            # Opens the image\n",
    "            with Image.open(path) as img:\n",
    "                # Loads the image as tuple of RGB values \n",
    "                pixel = img.load()\n",
    "                # Create two temporary lists\n",
    "                tempRGB, tempRow = [], []   \n",
    "                # Iterates by width and height (so every pixel)\n",
    "                for i in range(img.width):\n",
    "                    # Creates a new temporary list to help\n",
    "                    tempImage = []\n",
    "                    for j in range(img.height):\n",
    "                        # tempRGB will be a 1D list that has ALL of the RGB values not in tuple form\n",
    "                        tempRGB.extend([pixel[i, j][0], pixel[i, j][1], pixel[i, j][2]])\n",
    "                        # tempImage will be a 1D list that has the RGB for EACH ROW\n",
    "                        tempImage.append(np.asarray(pixel[i, j]))\n",
    "                    # tempRow appends each row of RGB values from tempImage so it will be a 2D list of rows and columns of RGB values\n",
    "                    # Essentially tempRow will make an image from rows of RGB values\n",
    "                    tempRow.append(tempImage)\n",
    "                # Each image in 2D will be appended to another list that will store all of the images from the directory\n",
    "                pokemonImage.append(tempRow)\n",
    "                # Takes the 1D array from tempRGB and appends it to one list\n",
    "                pokemonRGB.append(tempRGB)\n",
    "\n",
    "        # Takes all of the lists from above and uses thes scikit-learn Bunch class to create a Bunch object to use for Machine Learning\n",
    "        # This is why the data has to be made like so\n",
    "        # Referencing from our lecture and documentations, we can see that the machine learning algorithms for images uses Bunch for \n",
    "        # machine learning.\n",
    "        return Bunch( data=np.asarray(pokemonRGB), \n",
    "                      images=np.asarray(pokemonImage),\n",
    "                      target=np.asarray(pokemonTarget),\n",
    "                      target_names=np.asarray(pokemonNames) )\n",
    "\n",
    "    # Again, starts a timer to see how long it will take to create data\n",
    "    start = time.perf_counter()\n",
    "    pokemon_bunch_data = createData()\n",
    "    end = time.perf_counter()\n",
    "    # On average, it takes about 13 seconds or so to create data\n",
    "    print(f\"Time Elapsed to Create Data: {end-start:0.4f} seconds!\\n\")\n",
    "\n",
    "    # Function to debug code if the Bunch object is incorrectly done\n",
    "    def createDataDebug(pokemon_bunch_data):\n",
    "        print(pokemon_bunch_data['data'].shape)\n",
    "        print(pokemon_bunch_data['images'].shape)\n",
    "        print(pokemon_bunch_data['target'].shape)\n",
    "        print(pokemon_bunch_data['target_names'].shape)\n",
    "\n",
    "    # This part takes very long\n",
    "    forestData = []\n",
    "    forestData2 = []\n",
    "    knnData = []\n",
    "    knnData2 = []\n",
    "    for i in range(n):\n",
    "        # We are purposely having random_state = i so we can measure the difference in the parameters for each case\n",
    "        # Test size being 0.15 seems like a fair amount given the amount of images that we are working with\n",
    "        pokeTrain, pokeTest, labelTrain, labelTest = \\\n",
    "            train_test_split(pokemon_bunch_data['data'], pokemon_bunch_data['target'], test_size=0.15, random_state=i)\n",
    "\n",
    "        # For the sake of time, we have selected only two major cases that is of interest to compare\n",
    "        # It is being compared to the default value of RandomForest\n",
    "        # The paramater we are manipulating for RandomForest are:\n",
    "        #   n_estimators\n",
    "        #   criterion\n",
    "        #   min_samples_leaf\n",
    "        # Documetnation can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "        # To see what which parameter does\n",
    "        print(f\"#################### Training RandomForest Classifier #{i+1}\\n\")\n",
    "        start = time.perf_counter()\n",
    "        pokemonForest = RandomForestClassifier().fit(pokeTrain, labelTrain)\n",
    "        end = time.perf_counter()\n",
    "        score = pokemonForest.score(pokeTest, labelTest)\n",
    "        print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 100 trees!\\n\")\n",
    "        forestData.append(score)\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        pokemonForest = RandomForestClassifier(n_estimators=200, criterion='entropy').fit(pokeTrain, labelTrain)\n",
    "        end = time.perf_counter()\n",
    "        score = pokemonForest.score(pokeTest, labelTest)\n",
    "        print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 200 trees and entropy!\\n\")\n",
    "        forestData2.append(score)\n",
    "\n",
    "        # All other cases will not have their scores factored into the averages for the sake of skewing the accuracy.\n",
    "        # It is pretty interesting to run this once, however, to see the accuracy of all the other cases.\n",
    "        if otherCases:\n",
    "            start = time.perf_counter()\n",
    "            pokemonForest = RandomForestClassifier(criterion='entropy').fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score = pokemonForest.score(pokeTest, labelTest)\n",
    "            print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 100 trees and entropy!\\n\")\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            pokemonForest = RandomForestClassifier(criterion='entropy', min_samples_leaf=8).fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score = pokemonForest.score(pokeTest, labelTest)\n",
    "            print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 100 trees and entropy and min sample leaf of 8!\\n\")\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            pokemonForest = RandomForestClassifier(criterion='log_loss').fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score = pokemonForest.score(pokeTest, labelTest)\n",
    "            print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 100 trees and log_loss!\\n\")\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            pokemonForest = RandomForestClassifier(criterion='log_loss', min_samples_leaf=8).fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score = pokemonForest.score(pokeTest, labelTest)\n",
    "            print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 100 trees and log_loss and min sample leaf of 8!\\n\")\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            pokemonForest = RandomForestClassifier(max_depth=3).fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score = pokemonForest.score(pokeTest, labelTest)\n",
    "            print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 100 trees with a max-depth of 3!\\n\")\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            pokemonForest = RandomForestClassifier(min_samples_leaf=8).fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score = pokemonForest.score(pokeTest, labelTest)\n",
    "            print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 100 trees with a min samples leaf of 8!\\n\")\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            pokemonForest = RandomForestClassifier(max_depth=3, min_samples_leaf=8).fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score = pokemonForest.score(pokeTest, labelTest)\n",
    "            print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 100 trees with a max-depth of 3 and a min sample leaf of 8!\\n\")\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            pokemonForest = RandomForestClassifier(n_estimators=200).fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score = pokemonForest.score(pokeTest, labelTest)\n",
    "            print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 200 trees!\\n\")\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            pokemonForest = RandomForestClassifier(n_estimators=200, criterion='entropy', min_samples_leaf=8).fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score = pokemonForest.score(pokeTest, labelTest)\n",
    "            print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 200 trees and entropy and min samples leaf of 8!\\n\")\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            pokemonForest = RandomForestClassifier(n_estimators=200, criterion='log_loss').fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score = pokemonForest.score(pokeTest, labelTest)\n",
    "            print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 200 trees and log_loss!\\n\")\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            pokemonForest = RandomForestClassifier(n_estimators=200, criterion='log_loss', min_samples_leaf=8).fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score = pokemonForest.score(pokeTest, labelTest)\n",
    "            print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 200 trees and log_loss and a min samples leaf of 8!\\n\")\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            pokemonForest = RandomForestClassifier(n_estimators=200, max_depth=3).fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score = pokemonForest.score(pokeTest, labelTest)\n",
    "            print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 200 trees and max-depth of 3!\\n\")\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            pokemonForest = RandomForestClassifier(n_estimators=200, max_depth=3, min_samples_leaf=8).fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score = pokemonForest.score(pokeTest, labelTest)\n",
    "            print(f\"Testing RandomForest with {score:0.4f}% Accuracy in {end-start:0.4f} seconds with 200 trees and max-depth of 3 and a min sample leaf of 8!\\n\")\n",
    "       \n",
    "        # It is being compared to the default value of kNN\n",
    "        # The paramater we are manipulating for kNN are:\n",
    "        #   n_neighbors\n",
    "        #   leaf_size\n",
    "        #   weights\n",
    "        # Documentation can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "        # To see what which parameter does\n",
    "        print(f\"#################### Training kNearestNeighbor Classifier #{i+1}\\n\")\n",
    "        start = time.perf_counter()\n",
    "        pokemonKNN = KNeighborsClassifier(n_neighbors = 7, leaf_size = 100, weights = \"distance\").fit(pokeTrain, labelTrain)\n",
    "        end = time.perf_counter()\n",
    "        score2 = pokemonKNN.score(pokeTest, labelTest)\n",
    "        print(f\"Testing kNN with {score2:0.4f}% Accuracy in {end-start:0.4f} seconds with 7 neighbors, leaf size 100, and distance method!\\n\")\n",
    "        knnData2.append(score2)\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        pokemonKNN = KNeighborsClassifier().fit(pokeTrain, labelTrain)\n",
    "        end = time.perf_counter()\n",
    "        score2 = pokemonKNN.score(pokeTest, labelTest)\n",
    "        print(f\"Testing kNN with {score2:0.4f}% Accuracy in {end-start:0.4f} seconds with 5 neighbors!\\n\")\n",
    "        knnData.append(score2)\n",
    "\n",
    "        # All other cases will not have their scores factored into the averages for the sake of skewing the accuracy.\n",
    "        if otherCases:\n",
    "            start = time.perf_counter()\n",
    "            pokemonKNN = KNeighborsClassifier(leaf_size = 100, weights = \"distance\").fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score2 = pokemonKNN.score(pokeTest, labelTest)\n",
    "            print(f\"Testing kNN with {score2:0.4f}% Accuracy in {end-start:0.4f} seconds with 5 neighbors, leaf size 100, and distance method!\\n\")\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            pokemonKNN = KNeighborsClassifier(n_neighbors = 3, leaf_size = 100, weights = \"distance\").fit(pokeTrain, labelTrain)\n",
    "            end = time.perf_counter()\n",
    "            score2 = pokemonKNN.score(pokeTest, labelTest)\n",
    "            print(f\"Testing kNN with {score2:0.4f}% Accuracy in {end-start:0.4f} seconds with 3 neighbors, leaf size 100, and distance method!\\n\")\n",
    "\n",
    "    # Outputs the accuracy of both machine learning algorithms to see how they stack up\n",
    "    # From even one trial run, we can see that randomForest is generally the better algorithm for handling images than kNN is\n",
    "    # by over 15 points every time. \n",
    "    print(f\"\"\"#################### Conclusion \\n\n",
    "Over {n} trial(s), default RandomForest has an average of {sum(forestData)/len(forestData):0.4f}% accuracy.\\n\n",
    "Over {n} trial(s), modded RandomForest has an average of {sum(forestData2)/len(forestData2):0.4f}% accuracy.\\n\n",
    "Over {n} trial(s), default kNN has an average of {sum(knnData)/len(knnData):0.4f}% accuracy.\\n\n",
    "Over {n} trial(s), modded kNN has an average of {sum(knnData2)/len(knnData2):0.4f}% accuracy.\\n\"\"\")\n",
    "\n",
    "# Use this by default for quick results. About 1 minute, may take awhile depend on your computer/laptop.\n",
    "poke_predict(1, False) \n",
    "\n",
    "# Run the bottom after running the above to see other performances. About 2 minutes 20 minutes or so\n",
    "# poke_predict(1, True)\n",
    "\n",
    "# Run to see the aggregate average over 10 trials, or more. About 3 minutes and 30 seconds or so\n",
    "# poke_predict(10, False)\n",
    "\n",
    "# The following below is a example of running poke_predict 10 times: \n",
    "\n",
    "#################### Conclusion \n",
    "\n",
    "# Over 10 trial(s), default RandomForest has an average of 0.8432% accuracy.\n",
    "\n",
    "# Over 10 trial(s), modded RandomForest has an average of 0.8523% accuracy.\n",
    "\n",
    "# Over 10 trial(s), default kNN has an average of 0.6355% accuracy.\n",
    "\n",
    "# Over 10 trial(s), modded kNN has an average of 0.7236% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f45ea5469560aa4668c581526e66a99894cb446237ecc3d1847d6a714bdb791f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
